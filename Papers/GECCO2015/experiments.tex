\vspace{-0.5em}
\section{Experiments}

To assess the improvement of our Deep Parameter Tuning approach, we compared it with Shallow Parameter Tuning: 
 

\begin{description}
 \item[RQ1] {\bf How much performance improvement, with respect to the unmodified program, can be obtained by Shallow Parameter Turning using random search or NSGA-II? }
\end{description}

We consider RQ1 to provide a baseline result against which we compare the results from Deep Parameter Tuning.
%To mimic a traditional Shallow Parameter Tuning approach, 
We used NSGA-II algorithm (described in Section~\ref{sec_nsgaii}) and Random algorithm to search for better values for the shallow parameters in \emph{dlmalloc}, then compare the performance with \emph{dlmalloc}'s default configuration. 
%To answer this question, we compared the performance of the optimised configuration found by NSGA-II with the default \emph{dlmalloc} configuration and the best configurations found by random search with the same computation budget.  

\begin{description}
\item[RQ2] {\bf How ~much ~additional ~improvement ~can ~be achieved by our Deep Parameter Tuning algorithm compared with Shallow Parameter Tuning alone? }
\end{description}

We ask RQ2 to evaluate how useful our approach is at finding better configurations for the given non-functional properties. 
In these experiments, our Deep Parameter Tuning approach uses a custom mutation analysis to identify the most sensitive parts of the program, 
followed by an application of NSGA-II to optimise both explicit and implicit parameters for \emph{dlmalloc}. 

\begin{description}
\item[RQ3] {\bf What are the optimisation-time costs for these approaches to find their solutions? }
\end{description} 

Since our Deep Parameter Tuning approach exposes additional parameters
which are then optimised in conjunction with the baseline shallow
parameters, it may require extra resources at optimisation time.  
We thus measure the baseline cost of Shallow Parameter Tuning, as
well as the extra computation required by our Deep Parameter
Tuning. The user may use this gain/cost ratio to
decide whether to employ Shallow or Deep Parameter Tuning.

\subsection{Experiment Target}

%Dynamic memory allocation is an essential activity in many applications. It
%most commonly happens when an application requires memory of a size that 
%cannot be determined until runtime.
%Most systems support some system calls that could dynamically assign some memory to an application. When an application asks for some dynamic memory from the operating system, the simplest way is to give the exact size of memory it requests through these system calls, and to retrieve that memory back as soon as the application frees it. However, these allocation and deallocation system calls are usually much slower than other operations. So frequently allocating memory directly from the system is impractical for most of the applications. 

%Memory allocators have been introduced and developed to solve this problem using different allocation strategies. Usually applications communicate with the operating system in terms of memory only through their memory allocators. The idea of these allocators is to try to hold and manage some extra memory to satisfy subsequent memory requests from the application as effiecently as possible. On the other hand, when a piece of memory is freed by the application, before being released to the system, it is handled by memory allocators in case there is a memory request for the same size in the near future. The allocator is thus a buffer between an application and the system. Different memory management approaches significantly influence the performance of an application in terms of both memory and time.

Many memory allocation strategies and managers have been proposed and studied by many researchers to efficiently manage dynamic memory. Among them, Doug Lea's malloc (\emph{dlmalloc}) is ``among the fastest, most space-conserving, tunable, and portable general purpose allocators''~\cite{lea1996memory}. A study of Berger et al.~\cite{Berger:2002:RCM:582419.582421} shows that many other custom memory allocators do not perform significantly better than \emph{dlmalloc}, and are sometimes worse. We focus on \emph{dlmalloc} as an indicative starting point and optimise its configuration to each of the subject applications.

\emph{Dlmalloc} is a general memory allocator for C
programs. Although it provides a number of configuration parameters,  
it is usually used with its default values. 
We call these configurable parameters provided by the original author
shallow parameters. In these experiments we consider the nine shallow
parameters that are more relevant to the tradeoff between runtime and
memory high-water-mark. Table~\ref{tab_dlmalloc_parameters} briefly
describes these shallow parameters. 

%For example, \textbf{MALLOC\_ALIGNMENT} represents a multiple of how many bytes all request sizes should be rounded up to. It is an essential parameter since many other parameters are derived from it to avoid incompatibility. Smaller MALLOC\_ALIGNMENT tends to save memory but may not be compatible with all applications. Table~\ref{tab_dlmalloc_parameters} lists all 9 Shallow Parameters and brief description for them.
%It keeps two set of segregated lists managing small and large size available chunks respectively. Each of the segregated lists is called a bin and there are 64 small bins and 64 large bins in \emph{dlmalloc} (Figure~\ref{fig_7}). For small bins, each one contains chunks in the exact same size, in which way insertion to or deletion from the list is very quick. For large bins, each bin is associated with a range of sizes and any free chunks within that range are stored in the corresponding bin in the ascending order. So managing large bins is more costly than small bins but fortunately large bins are less frequent than small bins. Apart from these bins, \emph{dlmalloc} also keeps a top chunk, which is always at the end of the heap so that it can be extended or trimmed without affecting other memory chunks. 

%The top chunk is used only when there is no available chunk in any bins that meets the memory request. If the request size is too large to be satisfied from the top chunk and bigger than a pre-defined threshold, \emph{dlmalloc} uses an \emph{mmap}-like system call to allocate this size of memory from the operating system directly. Or it tries to extend the top chunk using \emph{sbrk}-like system call, so that the extended top chunk is big enough to cover the request.
%When a chunk is freed by the application, it is put back to one of the bins according to its size, after which \emph{dlmalloc} occasionally coalesces contiguous free chunks to create bigger chunks. If the top chunk is enlarged by combining free chunks next to it, it could be trimmed if it is too large for the need of the application if the freed chunk was mapped directly from the system, it is released to the system immediately. 

% Intruduce the 9 parameters defined in Dlmalloc (1 paragraph)
% draw a table with "para name, type, range, default, comment"
\begin{table*}[htbp]
\centering
\caption{\emph{dlmalloc} selective shallow parameters made available by the developers and used in our experiments}
\label{tab_dlmalloc_parameters}
\resizebox{0.9\textwidth}{!}{
\begin{tabular}{|l|c|c|c|l|}
\hline
Name & Default & Range & Type & Description\\
\hline
MALLOC\_ALIGNMENT & $2*\mathit{sizeof}(void*)$ & (1 -- 16)$*\mathit{sizeof}(void*)$ & $2^n*\mathit{sizeof}(void*)$ & Alignment unit\\
%\hline
FOOTERS & \emph{false} & \emph{true} or \emph{false} & boolean & Additional information of each chunk\\
%\hline
INSECURE & \emph{false} & \emph{true} or \emph{false} & boolean & Secure check\\
%\hline
NO\_SEGMENT\_TRAVERSAL & \emph{false} & \emph{true} or \emph{false} & boolean & Traversal of chunks before coalescing\\
%\hline
MORECORE\_CONTIGUOUS & \emph{true} & \emph{true} or \emph{false} & boolean & Contiguous heap extension support\\
%\hline
DEFAULT\_GRANULARITY & 0 & 4 KB -- 512 KB or 0 & $2^n$ KB or 0 & Unit of heap extension\\
%\hline
DEFAULT\_TRIM\_THRESHOLD & 2048 KB & 64 KB -- 16 MB & $2^n$ KB & Threshold of trimming\\
%\hline
DEFAULT\_MMAP\_THRESHOLD & 256 KB & 16 KB -- 2 MB & integer & Threshold of direct memory mapping\\
%\hline
MAX\_RELEASE\_CHECK\_RATE & 4095 & 1000 -- 10000 & integer & Frequency of coalescing\\
\hline
\end{tabular}}
\end{table*}


\subsection{Experiment Setup}

For our evaluation, we selected four applications: \emph{espresso}, \emph{gawk}, \emph{flex} and \emph{sed}. \emph{Espresso} is a fast application for simplifying complex digital electronic gate circuits. We use the \emph{espresso} benchmark source code and test cases from the \emph{DieHard} project~\cite{Berger:2006:DPM:1133981.1134000}. \emph{Gawk} is the GNU \emph{awk} implementation for string processing. We collect Version 4.1.0 of this application, as well as its test suite, from the GNU archives. \emph{flex} is a tool for generating scanners, programs which recognizes lexical patterns in text, and \emph{sed} is an editor that automatically modifies files given a set of rules. We obtain these last two programs and corresponding test suites from the SIR repository~\cite{SIR2005}. Summary data for these subject programs is listed in Table~\ref{tab_sub_app}.

\begin{table}[tbhp]
\centering
\caption{Subject applications}
\label{tab_sub_app}
\resizebox{0.45\textwidth}{!}{
\begin{tabular}{|c|r|r|l|}
\hline
Name & Loc & \# Tests & Description \\
\hline
espresso & 13256 & 19 & Digital circuit simplification\\
%\hline
gawk & 45241 & 334 & String processing\\
%\hline
flex & 9597 & 62 & Fast lexical analyzer generator\\
%\hline
sed & 5720 & 362 & Special file editor\\
\hline
\end{tabular}}
\end{table}

\subsection{Experiment Procedures}

We first used the shallow parameters only and applied the NSGA-II algorithm
with a population of 50 for 300 generations, using 5000 randomly generated
chromosomes as seeds. 
% FIXME: We have to say something about where these numbers came from. 
% Fan says the following.
These standard values were chosen after a few trial experiments to have the best performance and ensure convergent result for the algorithms. 
A random search was also applied with the same computation budget in optimising the shallow parameters. 

We used the open source C mutation testing tool MILU \cite{Harman:2011:SHO:2025113.2025144,JiaH08a} to automatically generate mutants from the selective operators shown in Table \ref{tab:cmop}. This mutation based pre-analysis finds the equivalent mutants that are sensitive to the non-functional properties under optimisation. These equivalent mutants are transformed and exposed into 9 deep parameters (the same number as the provided shallow parameters for a fairer comparison) for each subject program separately, as described in Section~\ref{sec_deep_parameter_optimisation}. Combining shallow and deep parameters, we again applied NSGA-II and random search with other identical experimental settings. All experiments were repeated for 20 runs to admit statistical analyses. 

All experiments were carried out on desktop machines with a quad-core CPU and 7.7 GB memory runing 64-bit Ubuntu 14.04. We used \emph{dlmalloc} version 2.8.6, which was compiled with gcc 4.8.1 with -O3 option. To capture the execution time and memory consumption precisely, we developed our own performance tool to measure the CPU time and the high-water-mark vitural memory consumption (see Section~\ref{sec_nsgaii}). The tool is publicly available at \url{https://github.com/FanWuUCL/memory}.

