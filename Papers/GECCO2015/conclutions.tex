\section{Conclusions}

In this paper we propose an automatic algorithm for discovering and
optimising deep parameters to tune programs with respect to non-functional
properties.  In particular, we focus on tuning \emph{dlmalloc}, a memory
allocator, to reduce the time and memory high-water-mark requirements of
off-the-shelf programs. Our approach combines a mutation analysis to
discover sensitive deep parameters as well as an SBSE approach which 
subsequently optimises these parameters, while retaining the functionality expressed in
a test suite.  In a series of experiments involving over 70,000 lines of
code and 700 test cases we found that our deep parameter approach
outperformed baseline optimisations (which use only the programmer-provided
shallow parameters), ultimately improving execution time by 12\% 
and memory consumption by 21\% in the best cases. In addition, despite
the larger search space considered, the additional optimisation time cost
of our approach is acceptably low. Overall we feel that deep parameter tuning 
approaches show much promise for the automated improvement of software
with respect to non-functional properties.  

% FIXME: Wes Weimer found the entire conclusion below to be very hard to
% follow, so I rewrote it entirely with the text above. You should check
% that text as a starting point make sure, for example, that it does not
% contain any falsehoods.

% Fan checked the text above and it's all correct. 

% In this paper, we use Shallow Parameter Tuning to adjust a general-purpose
% memory allocator, \emph{dlmalloc}, to each of four subject applications. In
% the experiments, multi-objective optimization is applied considering
% applications' time and memory consumption. It turns out that by Shallow
% Parameter Tuning, the best general-purpose memory allocator can be improved
% on a specific application. Beyond that, we expose more tunable parameters
% from the original program according to the sensitivity information derived
% from evaluating variants generated by applying Mutation Operators to the
% original. By tuning these Deep Parameters, we are able to find generally
% better solutions on the Pareto front on 3 out of 4 subjects. 
% To have a quantitive understanding on the computation cost of deep parameter tuning approach, we compare the time cost by each algorithm and show that by putting a little extra effort, we can achieve much better performance by deep parameter tuning.
