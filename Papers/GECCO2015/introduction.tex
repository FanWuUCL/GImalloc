
\section{Introduction}

To achieve optimal performance, many software systems need to be configured according to workload and running environment. 
Software developers often expose a set of parameters for users to re-configure such software systems adaptively.
However, manual parameter tuning is a demanding challenge because users are usually required not only to have extensive knowledge about the system and the workload, but also to balance many competing objectives, such as memory consumption and execution time.

Many studies have reported on the challenge of automated parameter tuning \cite{Hoffmann:2011:DKR:1950365.1950390, Vuduc01statisticalmodels,autotuning,Whaley:1998:ATL:509058.509096,Tapus:2002:AHT:762761.762771, hutter2009paramils,arcuri-ssbse-2011}. Early work attempted to find optimal values with mathmatical approaches \cite{Vuduc01statisticalmodels,autotuning,Whaley:1998:ATL:509058.509096,Tapus:2002:AHT:762761.762771}, while SBSE \cite{Harman:2007:CSF:1253532.1254729} has been used in more recent research \cite{hutter2009paramils,arcuri-ssbse-2011, Hoffmann:2011:DKR:1950365.1950390} on this problem. Although these approaches can automatically re-configure a system, their improvements are limited to those achievable with the given parameters.


Many software systems contain undocumented internal variables or even expressions (those can be evaluated as concrete values) that also affect the performance of the systems. Thus, these elements could also be good candidates for automated parameter tuning. However, many of these elements are `private', and therefore cannot be affected by changing the exposed parameters or API calls. Moreover, some internal values may not even be stored in variables, private or otherwise, but may merely exist as fleeting sub-expression evaluation outcomes. Identifying these variables and expressions is very difficult for general users, as it requires a deep understanding of the source code of the system. 


In this paper, we propose an automatic technique to discover internal variables and expressions that normally cannot be accessed directly, but impact on non-functional properties of interest. Our goal is to expose new parameters that can directly influence the values of these internal variables and expressions. To distinguish from parameters exposed by software designer (which we call ``Shallow Parameters''), we call these exposed parameters ``Deep Parameters'' \cite{Harman:2014:GIA:2593929.2600116}. Modifying shallow parameter values does not necessarily change the internal code elements represented by deep parameters. Therefore deep parameters provide additional opportunities for subsequent automated parameter tuning.


There has been an attempt to automate the process of exposing a limited form of `deep' parameters with the Software Tuning Panel for Autonomic Control (STAC) \cite{Brake:2008:ADS:1370018.1370031}. STAC first generates a design graph for a subject under optimisation. The design graph represents data reference transition flows in the subject. It then uses the reference patterns of shallow parameters to discover deep parameters, whose reference pattern is the same as one of the shallow parameter reference patterns. Although STAC can discover some deep parameters effectively, it suffers from two limitations. First, STAC requires initial human effort to characterise shallow parameters. Second, STAC can only find a subset of deep parameters; those that have similar data transition patterns to the known shallow parameters. To overcome these limitations, we apply a mutation-based sensitivity analysis to fully automated the process of locating potential deep parameters and subsequently apply NSGA II to search for optimal values for these parameters to balance non-functional properties of interest. 

In this paper, we focused on two non-functional properties, memory consumption and execution time, because they are important objectives for many applications and because they are naturally conflicting, thereby yielding a potentially interesting and rewarding multi-objective solution space. We illustrate the approach by re-configuring a general purpose memory allocator, \emph{dlmalloc}. We choose memory allocators, because they are critical to the memory consumption of a program and could take up to 60\% of the total execution time \cite{Zorn:1992:EMS:142181.142200}. As a result, memory optimisation is a widely studied topic \cite{Risco-Martin:2009:ODM:1569901.1570116,RiscoMartin2010572}. We evaluate our approach using four applications including benchmarks for \emph{dlmalloc} and real world applications.

The paper presents evidence that deep parameter optimisation is an effective approach to improve non-function properties for \emph{dlmalloc}. 
We report the results of experiments that show deep parameter optimisation competes favourably with shallow parameter optimisation and the default configuration. For all of our subjects, the deep parameter optimisation saves 21\% of wasted memory and reduces 12\% of execution time in the best case. We also investigate the deep parameters exposed by our approach are human-meaningful. The contributions of the paper are summarised as follows:


\begin{enumerate}

\item We introduce an automated approach to discover deep parameters, to enhance search-based parameter tuning.

\item We report the results of an empirical study comparing the shallow parameter tuning approach with our approach. On 4 real world applications, the results show that our approach can save 21\% of wasted memory and reduce 12\% of execution time, whereas shallow tuning alone achieves 10\% time and 16\% memory consumption reduction correspondingly. 

\item Further more, we report the computation time our approach, showing that the our approach, compared with shallow parameter tuning, can improve the memory saving by 14\%, by costing 13\% extra computation time, or cost little additional time (0.7\%) if it can not find better configuration than shallow parameter tuning.
%We also report a further investigation on the deep parameters found by the mutation based sensitivity analysis. The results suggest that these parameters are meaningful to human developers and are good candidates to be promoted into explicit parameters. 

\end{enumerate}

%The rest of this paper is organised as follows. 
%Section 2 introduces the background of memory management and a popular general-purpose memory allocator \emph{dlmalloc}.
%Section 3 describes out adaptive deep parameter tuning approach.
%Section 4 explains the experimental methods for the empirical study, the results of which are discussed in Section 5
%Section 6 discusses related work, and the paper concludes with Section 7.


