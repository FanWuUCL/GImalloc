
\documentclass{sig-alternate}
\usepackage{graphicx}
\usepackage{subfigure}
%\usepackage{subfig}
\usepackage{multirow}
\graphicspath{{pics/}}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[sort]{natbib}
%\usepackage[]{algorithm2e}


\begin{document}

 \conferenceinfo{GECCO'15,} {July 11-15, 2015, Madrid, Spain.}
    \CopyrightYear{2015}
    \crdata{TBA}
    \clubpenalty=10000
    \widowpenalty = 10000

\title{Deep Parameter Optimisation}

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor Fan Wu, Mark Harman, Yue Jia and Jens Krinke\\
       \affaddr{CREST, UCL, London, UK}
       %\affaddr{London, UK}
       %\affaddr{London WC1E 6BT, United Kingdom}\\
       %\email{fan.wu.12@ucl.ac.uk}
% 2nd. author
\alignauthor Westley Weimer\\
       \affaddr{University of Virginia}\\
       \affaddr{USA}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}

%
%An efficient memory allocator can help operating system save memory and make program applications run faster. This paper introduces a deep parameter optimisation technique to improve two non-functional properties, memory consumption and execution time for general purpose memory allocators. The approach extracts deep and shallow parameters to  adaptively re-tuning a memory allocator for a given specific program.
%We report experiments that show the deep parameter optimisation competes with the shallow parameter optimisation and the default configurations. For \# real world subjects, the deep parameter optimisation saves x\% of memory and reduce y\% of execution time overall.  We also present reasons why the implicit parameters exposed by our approach are meaningful to human developer. Deep parameter optimisation is thus a promising way to improve non-functional property for memory allocators.
%

%In Software Engineering, it is almost impossible for developers to both implement desired functionalities and optimise multiple non-functionalities, especially when they are all important to users but conflicting each other. There are many search-based approaches that automatically optimise these properties by tuning the parameters designed by developers of an application, or `shallow' parameters.
%However, the potential improvement of an application is limited by the design of these parameters. 
%In this paper, we proposea mutation-based approach to automatically discover and expose `deep' parameters, by tuning which we may break through the limit. We apply the approach on \emph{dlmalloc}, widely used C memory allocator, to show how this approach can achieve high performance on execution time and memory consumption of 4 subject programs. The results show that we can achieve 16\% and 21\% reduction on execution time and wasted memory respectively. In 3 out of 4 subjects, deep parameter tuning achieves a reduction rate on memory consumption that can never be achieved by shallow parameter tuning.

We introduce a mutation-based approach to automatically discover and expose `deep' (previously unavailable) parameters that affect a program's runtime costs.
These discovered parameters, together with existing (`shallow') parameters, form a search space that we tune using SBSE in a bi-objective formulation that optimises both time and space.
We implemented our approach and evaluated it on four real-world programs.
The results show that we can improve execution time by 12\% or achieve a 21\% space reduction in the best cases.
In three subjects, our deep parameter tuning represents a significant improvement over the baseline of shallow parameter tuning,
demonstrating the potential value of our deep parameter extraction approach.

\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Theory}

\keywords{Parameter tuning, parameter exposure, dynamic memory allocator} % NOT required for Proceedings


\input{introduction}
\input{motivation}
\input{methods}
\input{experiments}
\input{results}
\input{threat}
\input{relatedwork}
\input{conclutions}
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
Fan Wu is sponsored by Chinese Scholarship Council.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{myReading}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns

\balancecolumns
% That's all folks!
\end{document}
