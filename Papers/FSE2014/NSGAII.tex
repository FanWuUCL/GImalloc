\subsection{Exposing deep parameters}
The second step is to expose deep parameters which allow users to modify the value of the expression at selected locations. Based on the type of mutation, we first classify the selected mutants into two sets. $Set\ 1$ contains mutants generated from CRCR, OAAN, OAAA and OIDO operators, which simulate locations with non-logical expressions. $Set\ 2$ constrains mutants generated from the OCNG, OLLN, OLNG and ORRN operators, which simulate locations with logical expressions. 
Given an location $L$, $E_L$ is the expression at the location $L$, we use the following transformation rules to rewrite $E_L$ with a new parameter $v$.

\begin{equation}
 E_L \rightarrow \left\{
  \begin{array}{l l}
    (E_L + v) & \quad \text{if $L$ $\in$ Set 1}\\
    (E_L) \ xor \ v & \quad \text{if $L$ $\in$ Set 2}
    \end{array} \right.
\end{equation}

We use addition to affect the value of non-logical expression and exclusive or to affect the logical ones.
Finally we expose $v$ as a `public' parameter so that users can assign value to $v$ through parameter passing or APIs.

\subsection{MultiObjective Paramter optimisation}
\label{sec_nsgaii}
The expose Deep Parameters may provide extra impact on the program but still cannot substitute the Shallow Parameters. So in this work, we combine the Shallow Parameters and Deep Parameters and optimize them at the same time. For parameter optimisation, NSGA II\cite{996017}, a multi-objective Genetic Algorithm, is applied on the searching of the optimal values for both Shallow and Deep Parameters.
% data representation
We use linear representation to keep each candidate, in which each gene is an integer number representing one of the parameters. For mutation, we randomly increment or decrement it within its legitimate scope. And two-point crossover is applied while tournament selection is used for choosing breeding parents.
% fittness evaluation

We compile \emph{dlmalloc} to a shared object and each application is compiled and linked to that shared object at the beginning of each experiment. In each generation, after new candidates are generated through mutation and crossover operators, \emph{dlmalloc} is re-compiled with the values represented by each candidate and the given subject application using modified \emph{dlmalloc} is profiled on the non-functional properties of interest.
Currently we focus on two non-functional properties: time and memory consumption. \emph{Glibc}'s \emph{wait4} system call is used to calculate the total cpu time consumed by the application, while we compute the high-water mark of the memory consumption by instrumentation. In this way the memory consumption measured is virtual memory, while the physical pages allocated to an application is not always deterministic but depends on the work load and the system so that measuring the physical memory usage could be hard and misleading.

After the non-functional properties of interest of each candidate is profiled, NSGA II non-dominated selection is applied to create the next generation.

