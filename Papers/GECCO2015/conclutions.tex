\section{Conclusions}
In this paper, we use Shallow Parameter Tuning to adjust a general-purpose memory allocator, \emph{dlmalloc}, to each of four subject applications. In the experiments, multi-objective optimization is applied considering applications' time and memory consumption. It turns out that by Shallow Parameter Tuning, the best general-purpose memory allocator can be improved on a specific application. Beyond that, we expose more tunable parameters from the original program according to the sensitivity information derived from evaluating variants generated by applying Mutation Operators to the original. By tuning these Deep Parameters, we are able to find generally better solutions on the Pareto front on 3 out of 4 subjects. 
To have a quantitive understanding on the computation cost of deep parameter tuning approach, we compare the time cost by each algorithm and show that by putting a little extra effort, we can achieve much better performance by deep parameter tuning.
%In order to understand the Deep Parameters, we manually inspect them and find 12 out of 23 distinct Deep Parameters are reasonable to be exposed, based on our understanding of the program. By statistically analyzing the results, we believe the Deep Parameter Tuning is an effective and interesting approach that worth further investigation.
